{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c85db8a4",
   "metadata": {},
   "source": [
    "###### ==================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b51fb92",
   "metadata": {},
   "source": [
    "# Web Scraping & Dumping File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15adde18",
   "metadata": {},
   "source": [
    "###### ==================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2822f3e1",
   "metadata": {},
   "source": [
    "### Run Command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07659dbe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy-financial in c:\\users\\dell\\anaconda3\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from numpy-financial) (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "%run \"C:\\\\Users\\DELL\\\\Desktop\\\\Projects\\\\Wealth Management System\\\\Python\\\\General Files\\\\Libraries.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3f3c3ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy-financial in c:\\users\\dell\\anaconda3\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\dell\\anaconda3\\lib\\site-packages (from numpy-financial) (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "%run \"C:\\\\Users\\DELL\\\\Desktop\\\\Projects\\\\Wealth Management System\\\\Python\\\\General Files\\\\SQL_Connection_File.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e2ef64",
   "metadata": {},
   "source": [
    "### Class: Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b69b06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Web_Scraping_Data:\n",
    "    def __init__(self, base_link, driver_path, sql_connector, table_name):\n",
    "        \"\"\"\n",
    "        Initializes the Mutual_Fund class.\n",
    "\n",
    "        Args:\n",
    "            base_link (str): The base URL for the mutual fund data.\n",
    "            driver_path (str): The path to the Chrome WebDriver executable.\n",
    "            sql_connector: An SQL connector object for database operations.\n",
    "            table_name (str): The name of the SQL table to insert data into.\n",
    "        \"\"\"\n",
    "        self.url = base_link \n",
    "        self.driver_path = driver_path\n",
    "        self.sql_connector = sql_connector\n",
    "        self.table_name = table_name\n",
    "        \n",
    "        self.driver = None  # Initialize WebDriver instance\n",
    "        self.current_date = None\n",
    "        \n",
    "    def Initialize_Driver(self):\n",
    "        \"\"\"\n",
    "        Initializes the WebDriver instance.\n",
    "        \"\"\"\n",
    "        service = Service(self.driver_path)\n",
    "        options = webdriver.ChromeOptions()\n",
    "        self.driver = webdriver.Chrome(service=service, options=options)\n",
    "    \n",
    "    def Close_Driver(self):\n",
    "        \"\"\"\n",
    "        Closes the WebDriver instance.\n",
    "        \"\"\"\n",
    "        if self.driver:\n",
    "            self.driver.quit() \n",
    "        \n",
    "    def Fetch_Links(self):\n",
    "        \"\"\"\n",
    "        Fetches mutual fund data from a website and returns it as a DataFrame.\n",
    "\n",
    "        Returns:\n",
    "            equity_mutual_fund_links (list): A list of equity mutual fund links.\n",
    "            fund_links (list): A list of fund links.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Initialize the WebDriver\n",
    "            self.Initialize_Driver()\n",
    "            driver = self.driver\n",
    "            \n",
    "            # Navigate to the equity funds page\n",
    "            driver.get(self.url)\n",
    "\n",
    "            # Extract links under \"Types of Equity Funds\" heading\n",
    "            equity_mutual_fund_links = []\n",
    "            # New list to store fund links\n",
    "            fund_links = []\n",
    "\n",
    "            market_cap_heading = driver.find_element(By.XPATH, '//strong[contains(text(), \"By Market Capitalization\")]')\n",
    "            market_cap_heading.click()  # Expand the section\n",
    "            market_cap_elements = driver.find_elements(By.XPATH, '//a[contains(@href, \"/equity/\") and not(contains(@href, \"/portfolio-details/\"))]')\n",
    "        \n",
    "            for element in market_cap_elements:\n",
    "                equity_mutual_fund_links.append(element.get_attribute(\"href\"))\n",
    "\n",
    "            # Iterate over the links to find fund links directly\n",
    "            for link in equity_mutual_fund_links:\n",
    "                driver.get(link)\n",
    "            \n",
    "                # Find all the fund links under this category\n",
    "                fund_elements = driver.find_elements(By.XPATH, '//div[@class=\"fundListing.performing-data\"]/a[contains(@href, \"/mutual-funds/\")]')\n",
    "            \n",
    "                for fund_element in fund_elements:\n",
    "                    fund_links.append(fund_element.get_attribute(\"href\"))\n",
    "\n",
    "                # Extract all links from the current page and add to fund_links\n",
    "                all_links_on_page = driver.find_elements(By.TAG_NAME, \"a\")\n",
    "                links = [a.get_attribute(\"href\") for a in all_links_on_page if a.get_attribute(\"href\")]\n",
    "                fund_links.extend(links)\n",
    "        \n",
    "            return equity_mutual_fund_links, fund_links\n",
    "\n",
    "        except Exception as e:\n",
    "            # Handle exceptions here, or at least log them for debugging\n",
    "            print(f\"An error occurred while fetching the Mutual Fund Data: {e}\")\n",
    "        \n",
    "        finally:\n",
    "            self.Close_Driver()\n",
    "            \n",
    "    def Scroll(self, driver, element):\n",
    "        \"\"\"\n",
    "        Scrolls the web page to a specific element.\n",
    "\n",
    "        Args:\n",
    "            driver: The WebDriver instance.\n",
    "            element: The element to scroll to.\n",
    "        \"\"\"\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", element)\n",
    "\n",
    "    def Wait(self, driver, by, value, timeout=10):\n",
    "        \"\"\"\n",
    "        Waits for an element to be present on the web page.\n",
    "\n",
    "        Args:\n",
    "            driver: The WebDriver instance.\n",
    "            by: The method to locate the element (e.g., By.XPATH).\n",
    "            value: The locator value for the element.\n",
    "            timeout (int): The maximum time to wait for the element (default is 10 seconds).\n",
    "\n",
    "        Returns:\n",
    "            The located element.\n",
    "        \"\"\"\n",
    "        return WebDriverWait(driver, timeout).until(EC.presence_of_element_located((by, value)))\n",
    "\n",
    "    def Scrape_Data(self, link):\n",
    "        \"\"\"\n",
    "        Scrapes and processes data from a mutual fund portfolio details page.\n",
    "\n",
    "        Args:\n",
    "            link (str): The URL of the portfolio details page.\n",
    "\n",
    "        Returns:\n",
    "        pd.DataFrame: A DataFrame containing the scraped data.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Initialize the WebDriver\n",
    "            self.Initialize_Driver()\n",
    "            driver = self.driver\n",
    "\n",
    "            # Check if the URL exists and is valid\n",
    "            response = requests.get(link)\n",
    "\n",
    "            if response.status_code >= 200 and response.status_code < 300:\n",
    "                # URL is valid, continue with scraping\n",
    "                pass\n",
    "            else:\n",
    "                # URL is not valid, return an empty DataFrame\n",
    "                return pd.DataFrame()\n",
    "\n",
    "            # Visit the portfolio details page\n",
    "            driver.get(link)\n",
    "\n",
    "            # Find the Fund Name from the URL\n",
    "            fund_name = link.split(\"/\")[-3].replace(\"-\", \" \")\n",
    "\n",
    "            # Wait for the \"Complete Current Stock Holdings\" heading to appear\n",
    "            complete_holdings_heading = self.Wait(driver, By.XPATH, '//div[@class=\"heading-4\" and contains(text(), \"Complete Current Stock Holdings\")]')\n",
    "            \n",
    "            # Check if the table exists\n",
    "            if not complete_holdings_heading:\n",
    "                return pd.DataFrame()\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            # Find the parent div containing the table using the full XPath\n",
    "            parent_div = self.Wait(driver, By.XPATH, '/html/body/div/div[8]/div[3]/div/div[6]')\n",
    "\n",
    "            # Scroll to the parent div containing the table\n",
    "            self.Scroll(driver, parent_div)\n",
    "\n",
    "            # Find the table within the parent div\n",
    "            stock_table = parent_div.find_element(By.CLASS_NAME, 'table')\n",
    "\n",
    "            # Extract the data from the table\n",
    "            rows = stock_table.find_elements(By.TAG_NAME, 'tr')\n",
    "            data = []\n",
    "            for row in rows[1:]:  # Skip the header row\n",
    "                cols = row.find_elements(By.TAG_NAME, 'td')\n",
    "                # Extract only the first four columns\n",
    "                row_data = [col.text.strip() for col in cols[:4]]\n",
    "                data.append(row_data)\n",
    "\n",
    "            # Create a pandas DataFrame with specific column names\n",
    "            dataframe = pd.DataFrame(data, columns=[\"Stocks\", \"Sectors\", \"% of holding\", \"Value in (Cr)\"])\n",
    "\n",
    "            # Rename columns\n",
    "            dataframe.rename(columns={\n",
    "                'Stocks' : 'StockName', \n",
    "                'Sectors' : 'Sector', \n",
    "                '% of holding' : 'PercentageAUM', \n",
    "                'Value in (Cr)' : 'HoldingValue'\n",
    "            }, inplace=True)\n",
    "            \n",
    "            # Clean and convert columns\n",
    "            def Convert_Columns(column):\n",
    "                # Clean the column by removing commas, percentages, \"Cr\", and double hyphens\n",
    "                cleaned_column = column.str.replace(',', '').str.replace('%', '').str.replace('Cr', '').str.replace('--', '')\n",
    "\n",
    "                # Convert the cleaned column to float, handling conversion errors by setting to NaN\n",
    "                cleaned_column = pd.to_numeric(cleaned_column, errors='coerce')\n",
    "\n",
    "                return cleaned_column\n",
    "\n",
    "            columns_to_convert = [\n",
    "                'PercentageAUM',\n",
    "                'HoldingValue'\n",
    "            ]\n",
    "\n",
    "            # Apply the clean_and_convert_column function to the specified columns\n",
    "            dataframe[columns_to_convert] = dataframe[columns_to_convert].apply(Convert_Columns)\n",
    "\n",
    "            # Add the Fund Name column\n",
    "            dataframe['FundName'] = fund_name\n",
    "\n",
    "            return dataframe\n",
    "\n",
    "        except Exception as e:\n",
    "            # Handle exceptions here, or at least log them for debugging\n",
    "            print(f\"Link with inadequate data: \", link)\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        finally:\n",
    "            self.Close_Driver()  # Close the WebDriver\n",
    "\n",
    "        \n",
    "    def Mutual_Fund_Data(self):\n",
    "        \"\"\"\n",
    "        Executes the mutual fund data scraping process.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Fetch equity mutual fund links and fund links\n",
    "            equity_mutual_fund_links, fund_links = self.Fetch_Links()\n",
    "            \n",
    "            # Filter fund_links to include only links containing \"/mutual-funds/\"\n",
    "            fund_links = [link for link in fund_links if \"/mutual-funds/\" and \"-direct-growth/\" in link]\n",
    "    \n",
    "            # Define a lambda function to modify the links\n",
    "            modify_link = lambda link: link[:-5] + \"portfolio-details/\" + link[-5:]\n",
    "            \n",
    "            # Apply the lambda function to each link in fund_links\n",
    "            portfolio_details_fund_links = [modify_link(link) for link in fund_links]\n",
    "            \n",
    "            # Define a lambda function to modify specific links\n",
    "            modify_link = lambda link: link.replace(\"-direct-growthportfolio-details//\", \"-direct-growth/portfolio-details/\")\n",
    "\n",
    "            # Apply the lambda function to each link in portfolio_details_fund_links\n",
    "            portfolio_details_fund_links = [modify_link(link) if \"-direct-growthportfolio-details//\" in link else link for link in portfolio_details_fund_links]\n",
    "            \n",
    "            for link in portfolio_details_fund_links:\n",
    "                scraped_dataframe = self.Scrape_Data(link)\n",
    "                \n",
    "                # Execute the data dumping process\n",
    "                self.sql_connector.Append_SQL_Table(self.table_name, self.current_date, scraped_dataframe)\n",
    "            \n",
    "            print(\"Executed Successfully!\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            # Handle exceptions here, or at least log them for debugging\n",
    "            print(f\"An error occurred during the dumping of the Mutual Fund Data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c192e640",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659d76be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link with inadequate data:  https://www.etmoney.com/mutual-funds/bank-of-india-large-and-mid-cap-equity-fund-direct-growth/portfolio-details/15834\n",
      "Link with inadequate data:  https://www.etmoney.com/mutual-funds/sundaram-large-and-mid-cap-fund-direct-growth/portfolio-details/15653\n",
      "Link with inadequate data:  https://www.etmoney.com/mutual-funds/canara-robeco-emerging-equities-fund-direct-growth/portfolio-details/16144\n",
      "Link with inadequate data:  https://www.etmoney.com/mutual-funds/lic-mf-large-and-mid-cap-fund-direct-growth/portfolio-details/28923\n",
      "Link with inadequate data:  https://www.etmoney.com/mutual-funds/invesco-india-growth-opportunities-fund-direct-growth/portfolio-details/16333\n",
      "Link with inadequate data:  https://www.etmoney.com/mutual-funds/franklin-india-equity-advantage-fund-direct-growth/portfolio-details/15553\n",
      "Link with inadequate data:  https://www.etmoney.com/mutual-funds/aditya-birla-sun-life-equity-advantage-fund-direct-growth/portfolio-details/15264\n",
      "Link with inadequate data:  https://www.etmoney.com/mutual-funds/axis-growth-opportunities-fund-direct-growth/portfolio-details/38318\n",
      "Link with inadequate data:  https://www.etmoney.com/mutual-funds/baroda-bnp-paribas-large-and-mid-cap-fund-direct-growth/portfolio-details/41556\n",
      "Link with inadequate data:  https://www.etmoney.com/mutual-funds/hsbc-large-and-mid-cap-fund-direct-growth/portfolio-details/39934\n",
      "Link with inadequate data:  https://www.etmoney.com/mutual-funds/mahindra-manulife-large-and-mid-cap-fund-direct-growth/portfolio-details/40870\n",
      "Link with inadequate data:  https://www.etmoney.com/mutual-funds/motilal-oswal-large-and-midcap-fund-direct-growth/portfolio-details/40811\n",
      "Link with inadequate data:  https://www.etmoney.com/mutual-funds/union-large-and-midcap-fund-direct-growth/portfolio-details/40858\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "\n",
    "# Defining the driver path\n",
    "Driver_Path = \"C:\\\\Users\\\\DELL\\\\Downloads\\\\chromedriver-win64\\\\chromedriver-win64\\\\chromedriver.exe\"\n",
    "\n",
    "# Defining the constructor link\n",
    "Base_Link = \"https://www.etmoney.com/mutual-funds/equity\"\n",
    "\n",
    "# Defining the table name\n",
    "Mutual_Fund_Data_Table_Name = \"MutualFundData\"\n",
    "\n",
    "# Initialize the CSV_Data class instance\n",
    "Dump = Web_Scraping_Data(Base_Link, Driver_Path, SQL_Connector, Mutual_Fund_Data_Table_Name)\n",
    "\n",
    "# Execute the data dumping\n",
    "Dump.Mutual_Fund_Data()\n",
    "\n",
    "t_end = time.time()\n",
    "\n",
    "print(\"\\nTime taken to dump the Web Scraped Files: \", round((t_end - t_start) / 3600, 0), \" Hours\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
